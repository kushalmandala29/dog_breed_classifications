{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress warnings and info logs\n",
    "\n",
    "# Disable oneDNN optimizations\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set the environment variable to suppress TensorFlow logs\n",
    "\n",
    "\n",
    "# Suppress TensorFlow logs at runtime\n",
    "tf.get_logger().setLevel('ERROR')  # Only show errors\n",
    "\n",
    "# Optional: Set the logging level for CPU-related logs if needed\n",
    "logging.getLogger('tensorflow_cpu').setLevel(logging.ERROR)\n",
    "\n",
    "# Load the model from the saved directory\n",
    "model = load_model('model.h5', compile=False)\n",
    "\n",
    "# Use the model for predictions or other tasks\n",
    "# Example: model.predict(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "# from keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.applications.inception_v3.preprocess_input(x, data_format=None)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "nasnet_preprocessor = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract features from the dataset by a given pretrained model\n",
    "img_size = (331,331,3)\n",
    "\n",
    "def get_features(model_name, model_preprocessor, input_size, data):\n",
    "\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(model_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False,\n",
    "                            input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    \n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extact_features(data):\n",
    "    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n",
    "    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n",
    "    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n",
    "    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n",
    "\n",
    "    final_features = np.concatenate([inception_features,\n",
    "                                     xception_features,\n",
    "                                     nasnet_features,\n",
    "                                     inc_resnet_features],axis=-1)\n",
    "    \n",
    "    print('Final feature maps shape', final_features.shape)\n",
    "    \n",
    "    #deleting to free up ram memory\n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('data/labels.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(labels['breed'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = load_img('data/test/ffd87c3e44faa0e3ee5fbbdc4c63b59b.jpg',target_size = img_size)\n",
    "img_g = np.expand_dims(img_g, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Feature maps shape:  (1, 2048)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
      "Feature maps shape:  (1, 2048)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Feature maps shape:  (1, 4032)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Feature maps shape:  (1, 1536)\n",
      "Final feature maps shape (1, 9664)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78a19c7a69e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78a19c7a69e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted label: dhole\n",
      "Probability of prediction): 100 %\n"
     ]
    }
   ],
   "source": [
    "test_features = extact_features(img_g)\n",
    "\n",
    "\n",
    "\n",
    "predg = model.predict(test_features)\n",
    "print(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\n",
    "print(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
